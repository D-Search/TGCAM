# unet_multiattention_train_fixed.py
import argparse
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from unet_multiattention import UNetWithAttention
from dataloader import get_loader
import os
import torch.backends.cudnn as cudnn

def setup_device():
    """è®¾ç½®è®¾å¤‡å¹¶æ£€æŸ¥GPU"""
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'
    os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
    
    print("ğŸ”§ è®¾å¤‡åˆå§‹åŒ–...")
    print(f"CUDA_VISIBLE_DEVICES: {os.environ.get('CUDA_VISIBLE_DEVICES')}")
    
    # æ£€æŸ¥CUDA
    cuda_available = torch.cuda.is_available()
    gpu_count = torch.cuda.device_count() if cuda_available else 0
    
    print(f"âœ… CUDAå¯ç”¨: {cuda_available}")
    print(f"âœ… æ£€æµ‹åˆ°GPUæ•°é‡: {gpu_count}")
    
    if cuda_available:
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            print(f"  GPU {i}: {props.name}")
            print(f"    å†…å­˜: {props.total_memory / 1024**3:.1f} GB")
        
        # å¯ç”¨cudnnåŠ é€Ÿ
        cudnn.benchmark = True
        cudnn.enabled = True
        
        device_ids = list(range(min(2, gpu_count)))  # æœ€å¤šä½¿ç”¨2ä¸ªGPU
        main_device = f'cuda:{device_ids[0]}'
        device = torch.device(main_device)
        
        print(f"ğŸš€ ä½¿ç”¨GPU: {device_ids}")
        return device, device_ids, True
    else:
        print("âš ï¸  CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUè®­ç»ƒ")
        device = torch.device('cpu')
        return device, [], False

def validate_data_paths(train_path):
    """éªŒè¯æ•°æ®è·¯å¾„å¹¶ä¿®å¤æ ¼å¼"""
    print("\nğŸ“ æ•°æ®è·¯å¾„éªŒè¯...")
    
    # å¯èƒ½çš„è·¯å¾„ç»„åˆ
    possible_image_paths = [
        os.path.join(train_path, 'image'),
        os.path.join(train_path, 'images'),
        train_path + '/image/',
        train_path + '/images/',
        os.path.normpath(train_path) + '\\image\\',
        os.path.normpath(train_path) + '\\images\\'
    ]
    
    possible_gt_paths = [
        os.path.join(train_path, 'mask'),
        os.path.join(train_path, 'masks'),
        os.path.join(train_path, 'label'),
        os.path.join(train_path, 'labels'),
        train_path + '/mask/',
        train_path + '/masks/',
        os.path.normpath(train_path) + '\\mask\\',
        os.path.normpath(train_path) + '\\masks\\'
    ]
    
    # æŸ¥æ‰¾å›¾åƒè·¯å¾„
    image_root = None
    for path in possible_image_paths:
        if os.path.exists(path):
            image_root = path
            print(f"âœ… æ‰¾åˆ°å›¾åƒè·¯å¾„: {image_root}")
            break
    
    if image_root is None:
        print("âŒ æœªæ‰¾åˆ°å›¾åƒç›®å½•ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„:")
        for path in possible_image_paths:
            print(f"  - {path}")
        return None, None
    
    # æŸ¥æ‰¾æ©ç è·¯å¾„
    gt_root = None
    for path in possible_gt_paths:
        if os.path.exists(path):
            gt_root = path
            print(f"âœ… æ‰¾åˆ°æ©ç è·¯å¾„: {gt_root}")
            break
    
    if gt_root is None:
        print("âŒ æœªæ‰¾åˆ°æ©ç ç›®å½•ï¼Œè¯·æ£€æŸ¥ä»¥ä¸‹è·¯å¾„:")
        for path in possible_gt_paths:
            print(f"  - {path}")
        return None, None
    
    # ç¡®ä¿è·¯å¾„æ ¼å¼æ­£ç¡®ï¼ˆä»¥åˆ†éš”ç¬¦ç»“å°¾ï¼‰
    image_root = os.path.normpath(image_root) + os.sep
    gt_root = os.path.normpath(gt_root) + os.sep
    
    print(f"ğŸ”„ æ ¼å¼åŒ–åçš„è·¯å¾„:")
    print(f"  å›¾åƒè·¯å¾„: {image_root}")
    print(f"  æ©ç è·¯å¾„: {gt_root}")
    
    # éªŒè¯æ–‡ä»¶æ•°é‡
    try:
        image_files = [f for f in os.listdir(image_root.rstrip(os.sep)) 
                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        gt_files = [f for f in os.listdir(gt_root.rstrip(os.sep)) 
                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        print(f"ğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
        print(f"  å›¾åƒæ–‡ä»¶: {len(image_files)} ä¸ª")
        print(f"  æ©ç æ–‡ä»¶: {len(gt_files)} ä¸ª")
        
        if len(image_files) == 0:
            print("âŒ å›¾åƒç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶")
            return None, None
        if len(gt_files) == 0:
            print("âŒ æ©ç ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ©ç æ–‡ä»¶")
            return None, None
            
        # æ˜¾ç¤ºç¤ºä¾‹æ–‡ä»¶
        if image_files:
            print(f"  å›¾åƒç¤ºä¾‹: {image_files[:3]}")
        if gt_files:
            print(f"  æ©ç ç¤ºä¾‹: {gt_files[:3]}")
            
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™: {e}")
        return None, None
    
    return image_root, gt_root

def train():
    # å‚æ•°è®¾ç½®
    parser = argparse.ArgumentParser()
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--batch_size', type=int, default=8)
    parser.add_argument('--lr', type=float, default=1e-4)
    parser.add_argument('--train_path', type=str,
                       default=r'C:\Users\Administrator\TGCAM\data\BUSI1',
                       help='Path to training dataset')
    parser.add_argument('--model_save_path', type=str,
                       default='unet_multiattention_model.pth',
                       help='Path to save trained model')
    parser.add_argument('--num_heads', type=int, default=8)
    parser.add_argument('--bilinear', action='store_true')
    parser.add_argument('--layer2_attention', action='store_true', default=True)
    parser.add_argument('--layer3_attention', action='store_true', default=True)
    parser.add_argument('--mlp_ratio', type=float, default=4.0)
    parser.add_argument('--reduction_ratio', type=int, default=4)
    parser.add_argument('--dropout', type=float, default=0.1)
    args = parser.parse_args()

    # è®¾ç½®è®¾å¤‡
    device, device_ids, use_gpu = setup_device()
    
    # éªŒè¯æ•°æ®è·¯å¾„
    image_root, gt_root = validate_data_paths(args.train_path)
    if image_root is None or gt_root is None:
        print("âŒ æ•°æ®è·¯å¾„éªŒè¯å¤±è´¥ï¼Œæ— æ³•ç»§ç»­è®­ç»ƒ")
        return

    # æ ¹æ®GPUæƒ…å†µè°ƒæ•´æ‰¹æ¬¡å¤§å°
    if use_gpu and len(device_ids) > 1:
        batch_size = args.batch_size
        print(f"ğŸš€ å¤šGPUæ¨¡å¼: ä½¿ç”¨æ‰¹æ¬¡å¤§å° {batch_size}")
    else:
        batch_size = max(2, args.batch_size // 2)  # CPUæˆ–å•GPUå‡å°æ‰¹æ¬¡
        print(f"âš¡ å•è®¾å¤‡æ¨¡å¼: ä½¿ç”¨æ‰¹æ¬¡å¤§å° {batch_size}")

    # åˆå§‹åŒ–æ¨¡å‹
    print("\nğŸš€ åˆå§‹åŒ–æ¨¡å‹...")
    model = UNetWithAttention(
        n_channels=3, 
        n_classes=1, 
        bilinear=args.bilinear,
        layer2_attention=args.layer2_attention,
        layer3_attention=args.layer3_attention,
        num_heads=args.num_heads,
        mlp_ratio=args.mlp_ratio,
        reduction_ratio=args.reduction_ratio,
        dropout=args.dropout
    )
    
    # å¤šGPUæ•°æ®å¹¶è¡Œ
    if use_gpu and len(device_ids) > 1:
        print(f"ğŸ”„ å¯ç”¨æ•°æ®å¹¶è¡Œï¼Œä½¿ç”¨ {len(device_ids)} ä¸ªGPU")
        model = nn.DataParallel(model, device_ids=device_ids)
    
    model = model.to(device)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    print(f"ğŸ“Š æ¨¡å‹é…ç½®:")
    print(f"  è®¾å¤‡: {device}")
    print(f"  GPUæ•°é‡: {len(device_ids)}")
    print(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")
    
    # è®¡ç®—å‚æ•°
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"  æ€»å‚æ•°: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")

    # ä¼˜åŒ–å™¨é…ç½®
    base_lr = args.lr
    if use_gpu and len(device_ids) > 1:
        adjusted_lr = base_lr * len(device_ids)  # çº¿æ€§ç¼©æ”¾
    else:
        adjusted_lr = base_lr
        
    print(f"  å­¦ä¹ ç‡: {adjusted_lr}")
    print(f"  æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {batch_size * max(1, len(device_ids))}")
    
    optimizer = optim.Adam(model.parameters(), lr=adjusted_lr, weight_decay=1e-4)
    criterion = nn.BCEWithLogitsLoss()

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', 
                                                   factor=0.5, patience=5)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    print("\nğŸ“¦ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
    try:
        train_loader = get_loader(
            image_root, 
            gt_root, 
            batchsize=batch_size, 
            trainsize=384,
            pin_memory=use_gpu,  # åªåœ¨æœ‰GPUæ—¶å¯ç”¨
            num_workers=2 if use_gpu else 0  # GPUæ¨¡å¼ä¸‹ä½¿ç”¨æ›´å¤šworkers
        )
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ!")
        print(f"  è®­ç»ƒæ ·æœ¬: {len(train_loader.dataset)}")
        print(f"  æ‰¹æ¬¡æ•°é‡: {len(train_loader)}")
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ•°æ®åŠ è½½å™¨å¤±è´¥: {e}")
        print("ğŸ’¡ è¯·æ£€æŸ¥ dataloader.py ä¸­çš„è·¯å¾„å¤„ç†é€»è¾‘")
        return

    # è®­ç»ƒå¾ªç¯
    best_loss = float('inf')
    train_losses = []
    
    print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒ...")
    print(f"  è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"  æ€»æ‰¹æ¬¡: {len(train_loader)}")
    
    for epoch in range(args.epochs):
        model.train()
        epoch_loss = 0.0
        num_batches = 0
        
        for i, (images, gts, names) in enumerate(train_loader):
            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡
            images = images.to(device, non_blocking=use_gpu)
            gts = gts.to(device, non_blocking=use_gpu)
            
            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = criterion(outputs, gts)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            epoch_loss += loss.item()
            num_batches += 1
            
            # æ‰“å°è¿›åº¦
            if (i + 1) % 10 == 0:
                current_lr = optimizer.param_groups[0]['lr']
                print(f'ğŸ“ˆ [{epoch+1}/{args.epochs}] æ­¥éª¤ [{i+1}/{len(train_loader)}], æŸå¤±: {loss.item():.4f}, LR: {current_lr:.6f}')
        
        # è®¡ç®—å¹³å‡æŸå¤±
        avg_loss = epoch_loss / num_batches if num_batches > 0 else 0
        train_losses.append(avg_loss)
        
        # æ›´æ–°å­¦ä¹ ç‡
        old_lr = optimizer.param_groups[0]['lr']
        scheduler.step(avg_loss)
        new_lr = optimizer.param_groups[0]['lr']
        
        # å­¦ä¹ ç‡å˜åŒ–æç¤º
        if new_lr < old_lr:
            print(f"ğŸ“‰ å­¦ä¹ ç‡ä» {old_lr:.6f} é™ä½åˆ° {new_lr:.6f}")
        
        # æ‰“å°epochç»Ÿè®¡
        current_lr = optimizer.param_groups[0]['lr']
        print(f'ğŸ¯ è½®æ¬¡ [{epoch+1}/{args.epochs}], å¹³å‡æŸå¤±: {avg_loss:.4f}, å­¦ä¹ ç‡: {current_lr:.6f}')
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_loss < best_loss:
            best_loss = avg_loss
            # å¤„ç†DataParallelåŒ…è£…
            if isinstance(model, nn.DataParallel):
                model_state_dict = model.module.state_dict()
            else:
                model_state_dict = model.state_dict()
                
            torch.save({
                'epoch': epoch + 1,
                'model_state_dict': model_state_dict,
                'optimizer_state_dict': optimizer.state_dict(),
                'loss': best_loss,
                'args': vars(args)
            }, args.model_save_path)
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒæŸå¤±: {best_loss:.4f}")

    # ä¿å­˜è®­ç»ƒè®°å½•
    try:
        with open("unet_multiattention_train_losses.txt", "w") as f:
            f.write("Epoch,Average Loss\n")
            for epoch, loss in enumerate(train_losses):
                f.write(f"{epoch+1},{loss:.6f}\n")
        print(f"âœ… è®­ç»ƒæŸå¤±è®°å½•å·²ä¿å­˜")
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜è®­ç»ƒè®°å½•å¤±è´¥: {e}")
    
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    print(f"  æœ€ä½³æ¨¡å‹: {args.model_save_path}")
    print(f"  æœ€ä½³æŸå¤±: {best_loss:.4f}")
    print(f"  æ€»è®­ç»ƒè½®æ¬¡: {args.epochs}")

if __name__ == '__main__':
    train()
